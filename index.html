<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="PAPER_TITLE - AUTHOR_NAMES">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="FIRST_AUTHOR_NAME, SECOND_AUTHOR_NAME">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>PAPER_TITLE - AUTHOR_NAMES | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@latest/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@latest/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <!-- TODO: Replace with your lab's related works -->
        <a href="https://hf618.github.io/COSMIC_Project/" class="work-item" target="_blank">
          <div class="work-info">
            <!-- TODO: Replace with actual paper title -->
            <h5>COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation</h5>
            <!-- TODO: Replace with brief description -->
            <p></p>
            <!-- TODO: Replace with venue and year -->
            <span class="work-venue">CVPR 2025</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <!-- TODO: Add more related works or remove extra items -->
        <a href="https://hf618.github.io/DTBS_Project/" class="work-item" target="_blank">
          <div class="work-info">
            <h5>DTBS: Dual-Teacher Bi-directional Self-training for Domain Adaptation in Nighttime Semantic Segmentation</h5>
            <p></p>
            <span class="work-venue">ECAI 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>

      </div>
    </div>
  </div>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">Beyond the Exploration-Exploitation Trade-off: A Hidden State Approach for LLM Reasoning in RLVR</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://hf618.github.io/" target="_blank">Fanding Huang</a><sup>1,*</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=p1zSpZIAAAAJ&hl=zh-CN" target="_blank">Guanbo Huang</a><sup>1,*</sup>,</span>
              <span class="author-block">
                <a href="https://anikifan.github.io/" target="_blank">Xiao Fan</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://openreview.net/profile?id=~Yi_He12" target="_blank">Yi He</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://mastervito.github.io/" target="_blank">Xiao Liang</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://github.com/Cevaaa" target="_blank">Xiao Chen</a><sup>1</sup>,</span>
              <br> <span class="author-block">
                <a href="https://openreview.net/profile?id=~Qinting_Jiang1" target="_blank">Qinting Jiang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.sigs.tsinghua.edu.cn/Faisal_en/main.psp" target="_blank">Faisal Nadeem Khan</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.jiangjingyan.com/" target="_blank">Jingyan Jiang</a><sup>3,†</sup>,</span>
              <span class="author-block">
                <a href="http://pages.mmlab.top/" target="_blank">Zhi Wang</a><sup>1,†</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Tsinghua Shenzhen International Graduate School, Tsinghua University</span>
              <span class="author-block"><sup>2</sup>University of California, Los Angeles</span>
              <span class="author-block"><sup>3</sup>Shenzhen Technology University</span>
            </div>

            <div class="is-size-5 publication-authors">
                <span class="eql-cntrb"><small><sup>*</sup>Indicates Equal Contribution &nbsp;&nbsp;&nbsp; <sup>†</sup>Indicates Corresponding Authors</small></span>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2509.23808.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/hf618/VERL" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- TODO: Replace with your Hugging Face URL -->
                <span class="link-block">
                  <a href="https://huggingface.co/papers/2509.23808" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-hugging-face"></i>
                  </span>
                  <span>Hugging Face</span>
                  </a>
                </span>
                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2509.23808" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/first.png" alt="Comparative analysis graph" style="width: 100%; height: auto; border: none;" title="Analysis Image">

      <h2 class="subtitle has-text-centered" style="margin-top: 1.5rem;">
        Figure 1: Comparative analysis with the responses of DeepSeek-R1-Distill-Qwen-7B in simpleRL test dataset. (a) Traditional metrics for exploitation and exploration are constrained by negative coupling, leading to meandering progress for both capabilities. (b) Our metrics are mutually independent. (c) Training regularization with our metrics demonstrates stronger performance in both exploitation (small K) and exploration (large K).
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            A prevailing view in Reinforcement Learning for Verifiable Rewards (RLVR) interprets recent progress through the lens of an exploration-exploitation trade-off, a perspective largely shaped by token-level metrics. We re-examine this perspective, proposing that this perceived trade-off may not be a fundamental constraint but rather an artifact of the measurement level. To investigate this, we shift the analysis to the semantically rich hidden-state space, adopting <strong>Effective Rank (ER)</strong> to quantify exploration and proposing its novel first- and second-order derivatives, named <strong>Effective Rank Velocity (ERV)</strong> and <strong>Effective Rank Acceleration (ERA)</strong>, to capture exploitation dynamics. Our analysis reveals that at the hidden-state level, exploration and exploitation could be decoupled. This finding reveals an opportunity to enhance both capacities simultaneously. This insight motivates our method, <strong>Velocity-Exploiting Rank-Learning (VERL)</strong>, the first to operationalize the principle of synergistic exploration-exploitation enhancement by directly shaping the RL advantage function. The key innovation is leveraging the theoretically stable ERA as a predictive meta-controller to create a synergistic, dual-channel incentive structure. Instead of forcing a trade-off, VERL prospectively amplifies rewards for exploration to preempt overconfidence and reinforces exploitative gains to consolidate reasoning. Experiments across diverse LLMs and reasoning benchmarks show consistent gains, including up to 21.4% absolute accuracy improvement on the challenging Gaokao 2024 dataset.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">  <h2 class="title is-3">Analysis</h2>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      <p>
        <strong>1. Analysis of Response-Level Metrics</strong>
      </p>
      <p>
         <strong>Semantic space of hidden states move beyond the exploration-exploitation trade-off towards stable enhancements.</strong> Instead of forcing a trade-off, RL training consistently enhances a model's exploitation capabilities (the rate of information gain), regardless of its baseline exploratory tendencies. This suggests exploration and exploitation can be improved simultaneously.
      </p>
      <p>
        <strong>Effective Rank Acceleration distinguishes correct reasoning.</strong> While high exploration (ER) or high velocity of information gain (ERV) can sometimes lead to errors, the acceleration of this gain (ERA) is a robust indicator that consistently distinguishes correct and robust reasoning paths from flawed ones.
      </p>
    </div>
    <div class="content has-text-centered" style="margin-top:1em;">
      <img src="static/images/observation1.png" alt="第一个分析的图片" style="width: 99%; border: 1px solid #ddd;"/>
      <figcaption style="text-align: center; margin-top: 0.5em; font-size: 0.9em; color: #555;">
        Figure 2: Response-level metrics during GRPO post-training, smoothed with a 10-step rolling window. Metrics are shown for the <span style="color:blue;">Overall</span> batch, as well as for subsets of <span style="color:rgb(0,140,0);">Correct</span> and <span style="color:red;">Incorrect</span> samples. The rightmost column displays the average <span style="color:rgb(107,30,120);">Critic Score</span> (reward) and <span style="color:orange;">Response Length</span> per batch.
      </figcaption>
    </div>

    <div style="height:30px;"></div>

    <div class="content has-text-justified">
      <p>
        <strong>2. Analysis of Response-Level Metrics</strong>
      </p>
      <p>
        <strong>Policy optimization correlates with expanding dataset-level diversity.</strong> As a model's performance improves, the semantic diversity of its reasoning strategies across the entire dataset expands. This is shown by a strong positive correlation between validation scores and our dataset-level ER, ERV, and ERA metrics.
      </p>
      <p>
        <strong>Effective Rank reveals refinement beyond the limits of conventional rank.</strong> Even late in training when a model seems to have a fixed number of reasoning strategies (i.e., conventional rank plateaus), a rising Effective Rank (ER) shows it is still subtly refining and optimizing its existing pathways for higher quality and efficiency.
      </p>
    </div>
    <div class="content has-text-centered" style="margin-top:1em;">
      <img src="static/images/observation2.png" alt="第二个分析的图片" style="width: 99%; border: 1px solid #ddd;"/>
      <figcaption style="text-align: center; margin-top: 0.5em; font-size: 0.9em; color: #555;">
      Figure 3: Visualization of dataset-level metrics during GRPO post-training. The figure compares <span style="color:rgb(36,65,171);">Traditional</span> metrics with our <span style="color:brown;">proposed</span> metrics. Also shown are the <span style="color:rgb(107,30,120);">Validation Score</span> and sample <span style="color:rgb(0,140,0);">Correctness</span>, both averaged over the validation dataset.
      </figcaption>
    </div>
  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Methodology</h2>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      <p>
        We propose <strong>Velocity-Exploiting Rank-Learning (VERL)</strong>, a method that moves beyond the trade-off between exploration and exploitation by directly shaping the RL advantage function using Effective Rank (ER) and Velocity (V). Instead of acting as a switch between the two capacities in a lower dimension, VERL functions as an <em>tuner</em> that synergistically enhances both capacities in a higher-dimensional space.
      </p>
      <p>
        Its key innovation is leveraging Acceleration (ERA) as a meta-control variable, a choice justified by our theoretical proof of its remarkable stability. Specifically, VERL uses ERA to create a synergistic, dual-channel incentive structure. Instead of switching between modes, it prospectively shapes the reward to simultaneously encourage exploration (via ER) to preempt overconfidence, while also reinforcing exploitative gains (via V) to consolidate the reasoning path. This unique stability makes ERA a robust signal to guide training, allowing VERL to simultaneously encourage exploration from productive-potential states while preventing overfitting to local optima.
      </p>
    </div>

    <div class="content has-text-centered" style="margin-top: 2em;">
      <img src="static/images/overview_01.png" alt="方法流程图" style="width: 99%; border: 1px solid #ddd;"/>
      <figcaption style="text-align: center; margin-top: 0.5em; font-size: 0.9em; color: #444;">
        Figure 4: Overview of VERL. 
        <span style="color:rgb(100,100,100);">Exploration</span> 
        is quantified by computing the 
        <span style="color:rgb(100,100,100);">Effective Rank (ER)</span> 
        of the rolling-done hidden states via SVD, while 
        <span style="color:rgb(50,150,200);">exploitation</span> 
        is captured through EMA-smoothed first-order difference 
        (<span style="color:rgb(50,150,200);">Effective Rank Velocity (ERV)</span>) 
        on per-step rolling hidden state and extended to second-order difference 
        (<span style="color:rgb(200,50,100);">Effective Rank Acceleration (ERA)</span>). 
        Finally, exploration and exploitation are adaptively integrated to derive the 
        <span style="color:rgb(255,200,50);">auxiliary advantage</span>.
      </figcaption>
    </div>
  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Experiments</h2>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      <h4 class="title is-4">Key Findings</h4>
      <ul style="padding-left: 20px; margin-top: 1em;">
        <li>
          <strong>VERL Generalizes Across Diverse Benchmarks:</strong> Our method demonstrates strong and consistent performance improvements on multiple mathematical reasoning benchmarks that vary in difficulty.
        </li>
        <li>
          <strong>Robustness Across RL Algorithms and Base Models:</strong> VERL shows broad applicability, successfully enhancing different base models (e.g., Llama, Qwen, Mistral) and integrating seamlessly with various RL algorithms like GRPO and PPO.
        </li>
        <li>
          <strong>Simultaneous Gains in Exploration and Exploitation:</strong> The method successfully enhances both model exploitation (reflected by significant gains in Pass@1 scores) and exploration (evidenced by improved Pass@k performance), moving beyond a simple trade-off.
        </li>
      </ul>
    </div>

    <div style="height:10px;"></div>

    <div class="content has-text-centered" style="margin-top: 1em;">
      <img src="static/images/Pass1.png" alt="Pass@1 Performance Comparison" style="width: 99%; border: 1px solid #ddd;"/>
      <figcaption style="text-align: center; margin-top: 0.5em; font-size: 0.9em; color: #555;">
      Figure 5: Performance comparison of models on mathematical reasoning benchmarks (Pass@1). 
      &ldquo;+ GRPO&rdquo; and &ldquo;+ PPO&rdquo; denote RL fine-tuning by GRPO and PPO framework respectively. 
      &ldquo;w/ VERL.&rdquo; indicates incorporating our VERL with original RL type. 
      &Delta; represents the performance contrast between original RL method and its VERL variant.
    </figcaption>
    </div>

    <div style="height:10px;"></div>

    <div class="content has-text-centered" style="margin-top: 1em;">
      <img src="static/images/Passk.png" alt="Pass@k Performance Comparison" style="width: 99%; border: 1px solid #ddd;"/>
      <figcaption style="text-align: center; margin-top: 0.5em; font-size: 0.9em; color: #555;">
        Figure 6: Performance comparison of instruction-tuned models under diverse decoding settings (Pass@<em>k</em>).
      </figcaption>
    </div>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{YourPaperKey2024,
  title={Your Paper Title Here},
  author={First Author and Second Author and Third Author},
  journal={Conference/Journal Name},
  year={2024},
  url={https://your-domain.com/your-project-page}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
